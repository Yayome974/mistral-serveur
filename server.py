#!/usr/bin/env python3
"""
Analyseur de cours intelligent - Version am√©lior√©e
- OCR gratuit avec Tesseract
- H√©bergement gratuit avec Vercel/Railway
- Nouvelles fonctionnalit√©s avanc√©es
"""

import os
import json
import time
import re
import base64
from datetime import datetime
from flask import Flask, request, jsonify, send_from_directory
from PIL import Image, ImageEnhance, ImageFilter
import io
import pytesseract
import cv2
import numpy as np
from dotenv import load_dotenv
import requests
from werkzeug.utils import secure_filename

# Configuration pour diff√©rents environnements de d√©ploiement
load_dotenv()

app = Flask(__name__)
app.config['MAX_CONTENT_LENGTH'] = 5 * 1024 * 1024  # 5MB max

# Configuration Tesseract selon l'environnement
if os.getenv('VERCEL') or os.getenv('RAILWAY'):
    # Pour les d√©ploiements cloud
    pytesseract.pytesseract.tesseract_cmd = '/usr/bin/tesseract'
else:
    # Pour le d√©veloppement local (Windows/Mac/Linux)
    if os.name == 'nt':  # Windows
        pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

# APIs gratuites alternatives
MISTRAL_API_KEY = os.getenv('MISTRAL_API_KEY')
HUGGINGFACE_API_KEY = os.getenv('HUGGINGFACE_API_KEY')  # Alternative gratuite
OLLAMA_URL = os.getenv('OLLAMA_URL', 'http://localhost:11434')  # Local AI

# Stockage en m√©moire pour la session (remplace localStorage)
session_data = {}

class CourseAnalyzer:
    def __init__(self):
        self.supported_formats = {'.jpg', '.jpeg', '.png', '.webp', '.bmp', '.tiff'}
        self.languages = {
            'fr': 'fra+eng',
            'en': 'eng',
            'es': 'spa+eng',
            'de': 'deu+eng'
        }

    def enhance_image_for_ocr(self, image_data):
        """Am√©liore la qualit√© de l'image pour un meilleur OCR"""
        try:
            # Conversion en numpy array pour OpenCV
            img_array = np.frombuffer(image_data, np.uint8)
            img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
            
            if img is None:
                # Fallback avec PIL
                pil_image = Image.open(io.BytesIO(image_data))
                img = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
            
            # Am√©lioration de l'image
            # 1. Conversion en niveaux de gris
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            
            # 2. R√©duction du bruit
            denoised = cv2.medianBlur(gray, 5)
            
            # 3. Am√©lioration du contraste
            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
            enhanced = clahe.apply(denoised)
            
            # 4. Binarisation adaptative
            binary = cv2.adaptiveThreshold(
                enhanced, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                cv2.THRESH_BINARY, 11, 2
            )
            
            # 5. Morphologie pour nettoyer
            kernel = np.ones((2,2), np.uint8)
            cleaned = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
            
            return cleaned
            
        except Exception as e:
            print(f"Erreur enhancement image: {e}")
            # Fallback simple avec PIL
            try:
                pil_image = Image.open(io.BytesIO(image_data))
                enhanced = ImageEnhance.Contrast(pil_image).enhance(2.0)
                enhanced = ImageEnhance.Sharpness(enhanced).enhance(1.5)
                return np.array(enhanced.convert('L'))
            except:
                return None

    def extract_text_with_tesseract(self, image_data, language='fra+eng'):
        """Extraction de texte avec Tesseract OCR (gratuit)"""
        try:
            print("üîç D√©marrage OCR Tesseract...")
            
            # Am√©lioration de l'image
            processed_image = self.enhance_image_for_ocr(image_data)
            
            if processed_image is None:
                # Fallback direct
                image = Image.open(io.BytesIO(image_data))
                processed_image = np.array(image.convert('L'))
            
            # Configuration Tesseract optimis√©e
            custom_config = r'--oem 3 --psm 6 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789√†√°√¢√§√®√©√™√´√¨√≠√Æ√Ø√≤√≥√¥√∂√π√∫√ª√º√ø√ß√±√Ä√Å√Ç√Ñ√à√â√ä√ã√å√ç√é√è√í√ì√î√ñ√ô√ö√õ√ú≈∏√á√ë.,;:!?()[]{}"\'-+*/%=<>&|@#$‚Ç¨ '
            
            # Extraction du texte
            extracted_text = pytesseract.image_to_string(
                processed_image, 
                lang=language, 
                config=custom_config
            )
            
            # Nettoyage du texte
            cleaned_text = self.clean_extracted_text(extracted_text)
            
            if len(cleaned_text.strip()) < 10:
                return None, "Tr√®s peu de texte d√©tect√©. V√©rifiez la qualit√© de l'image."
            
            print(f"‚úÖ Texte extrait: {len(cleaned_text)} caract√®res")
            return cleaned_text, None
            
        except Exception as e:
            return None, f"Erreur OCR Tesseract: {str(e)}"

    def clean_extracted_text(self, text):
        """Nettoie et am√©liore le texte extrait"""
        if not text:
            return ""
        
        # Corrections communes OCR
        corrections = {
            r'\b[Il1]\b': 'l',
            r'\b0\b': 'o',
            r'\brn\b': 'm',
            r'\bvv\b': 'w',
            r'\|': 'l',
            r'(?<=[a-z])(?=[A-Z])': ' ',  # Ajoute espace entre minuscule et majuscule
        }
        
        for pattern, replacement in corrections.items():
            text = re.sub(pattern, replacement, text)
        
        # Nettoyage g√©n√©ral
        text = re.sub(r'\s+', ' ', text)  # Espaces multiples
        text = re.sub(r'\n\s*\n', '\n\n', text)  # Lignes vides multiples
        
        return text.strip()

    def detect_content_type_auto(self, text):
        """D√©tection automatique du type de contenu"""
        text_lower = text.lower()
        
        # Mots-cl√©s par domaine
        keywords = {
            'mathematics': ['√©quation', 'th√©or√®me', 'fonction', 'd√©riv√©e', 'int√©grale', 'matrice', 'vecteur', 'g√©om√©trie'],
            'physics': ['force', '√©nergie', 'vitesse', 'acc√©l√©ration', 'onde', '√©lectron', 'atome', 'masse'],
            'chemistry': ['mol√©cule', 'atome', 'r√©action', 'acide', 'base', '√©l√©ment', 'liaison', 'ph'],
            'biology': ['cellule', 'adn', 'prot√©ine', 'enzyme', 'organisme', '√©volution', 'g√©n√©tique'],
            'history': ['guerre', 'r√©volution', 'si√®cle', 'roi', 'empire', 'bataille', 'trait√©', 'civilisation'],
            'literature': ['auteur', 'roman', 'po√®me', 'vers', 'm√©taphore', 'personnage', 'narration'],
            'philosophy': ['existence', 'conscience', 'morale', '√©thique', 'm√©taphysique', 'logique'],
            'economics': ['march√©', 'prix', 'demande', 'offre', 'inflation', 'monnaie', 'commerce']
        }
        
        scores = {}
        for domain, words in keywords.items():
            score = sum(1 for word in words if word in text_lower)
            scores[domain] = score
        
        if scores:
            detected = max(scores, key=scores.get)
            if scores[detected] > 2:
                return detected
        
        return 'general'

analyzer = CourseAnalyzer()

# APIs IA alternatives gratuites/locales
class AIProvider:
    def __init__(self):
        self.providers = ['mistral', 'huggingface', 'ollama', 'local']

    def query_huggingface(self, text, task_type="summarization"):
        """API Hugging Face gratuite (limit√©e)"""
        if not HUGGINGFACE_API_KEY:
            return None
            
        headers = {"Authorization": f"Bearer {HUGGINGFACE_API_KEY}"}
        
        # Mod√®les gratuits selon la t√¢che
        models = {
            "summarization": "facebook/bart-large-cnn",
            "question-generation": "mrm8488/t5-base-finetuned-question-generation-ap",
            "text-generation": "gpt2"
        }
        
        api_url = f"https://api-inference.huggingface.co/models/{models.get(task_type, 'gpt2')}"
        
        try:
            response = requests.post(api_url, headers=headers, json={"inputs": text[:1000]})
            if response.status_code == 200:
                return response.json()
        except:
            pass
        return None

    def query_ollama_local(self, prompt, model="llama3.2:1b"):
        """Ollama local (gratuit, n√©cessite installation)"""
        try:
            response = requests.post(
                f"{OLLAMA_URL}/api/generate",
                json={
                    "model": model,
                    "prompt": prompt,
                    "stream": False,
                    "options": {"temperature": 0.7}
                },
                timeout=60
            )
            if response.status_code == 200:
                return response.json().get('response', '')
        except:
            pass
        return None

ai_provider = AIProvider()

# Prompts am√©lior√©s avec nouvelles fonctionnalit√©s
ENHANCED_SYSTEM_PROMPT = """
Tu es Lya, une IA p√©dagogique avanc√©e sp√©cialis√©e dans l'analyse de cours. 
Tu es capable de cr√©er des ressources d'apprentissage personnalis√©es et interactives.

Nouvelles capacit√©s:
- D√©tection automatique du niveau (d√©butant/interm√©diaire/avanc√©)
- G√©n√©ration de cartes mentales textuelles
- Cr√©ation de quiz interactifs avec difficult√© progressive
- Suggestions de ressources compl√©mentaires
- Plans de r√©vision personnalis√©s
- Mn√©motechniques cr√©atives
"""

MASTER_ANALYSIS_PROMPT = """
TEXTE √Ä ANALYSER:
---
{text}
---

CONTEXTE D√âTECT√â: {content_type}
NIVEAU ESTIM√â: {level}

G√âN√àRE UNE ANALYSE COMPL√àTE avec les sections suivantes (utilise les balises XML exactes):

<section_resume>
## R√âSUM√â STRUCTUR√â
[R√©sum√© d√©taill√© avec points cl√©s et relations entre concepts]
</section_resume>

<section_niveau>
## ANALYSE DE NIVEAU
[Estime le niveau: d√©butant/interm√©diaire/avanc√© et explique pourquoi]
</section_niveau>

<section_concepts>
## CONCEPTS CL√âS HI√âRARCHIS√âS
[Liste les concepts par ordre d'importance avec d√©finitions]
</section_concepts>

<section_carte_mentale>
## CARTE MENTALE TEXTUELLE
[Structure arborescente des id√©es principales et leurs connexions]
</section_carte_mentale>

<section_questions_progressives>
## QUIZ PROGRESSIF (3 NIVEAUX)
### Niveau Facile:
[3 questions de base]
### Niveau Moyen:  
[3 questions d'application]
### Niveau Difficile:
[2 questions d'analyse/synth√®se]
</section_questions_progressives>

<section_mn√©motechniques>
## TECHNIQUES DE M√âMORISATION
[Moyens mn√©motechniques, acronymes, associations pour retenir les concepts]
</section_mn√©motechniques>

<section_plan_revision>
## PLAN DE R√âVISION PERSONNALIS√â
[Planning sur 7 jours avec objectifs quotidiens]
</section_plan_revision>

<section_ressources>
## RESSOURCES COMPL√âMENTAIRES SUGG√âR√âES
[Types de ressources √† chercher pour approfondir]
</section_ressources>

<section_evaluation>
## AUTO-√âVALUATION
[Grille de comp√©tences √† cocher pour mesurer sa compr√©hension]
</section_evaluation>
"""

def analyze_with_ai(text, content_type="general", detail_level="detailed"):
    """Analyse compl√®te avec IA (plusieurs providers)"""
    
    # D√©tection automatique du niveau
    level = "interm√©diaire"  # Par d√©faut
    if len(text) < 500:
        level = "d√©butant"
    elif len(text) > 2000 and any(word in text.lower() for word in ['th√©or√®me', 'd√©monstration', 'corollaire', 'axiome']):
        level = "avanc√©"
    
    full_prompt = MASTER_ANALYSIS_PROMPT.format(
        text=text, 
        content_type=content_type, 
        level=level
    )
    
    # Essai avec diff√©rents providers
    providers = [
        ("Mistral API", lambda: query_mistral_api(ENHANCED_SYSTEM_PROMPT, full_prompt)),
        ("Hugging Face", lambda: ai_provider.query_huggingface(text)),
        ("Ollama Local", lambda: ai_provider.query_ollama_local(full_prompt)),
        ("Analyse locale", lambda: generate_local_analysis(text, content_type, level))
    ]
    
    for provider_name, provider_func in providers:
        try:
            print(f"ü§ñ Tentative avec {provider_name}...")
            result = provider_func()
            if result and len(result) > 100:
                print(f"‚úÖ Analyse r√©ussie avec {provider_name}")
                return result
        except Exception as e:
            print(f"‚ùå √âchec {provider_name}: {e}")
            continue
    
    # Fallback analysis locale si tout √©choue
    return generate_local_analysis(text, content_type, level)

def query_mistral_api(system_prompt, user_prompt):
    """Query Mistral avec gestion d'erreurs am√©lior√©e"""
    if not MISTRAL_API_KEY:
        return None
        
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {MISTRAL_API_KEY}'
    }
    
    payload = {
        "model": "mistral-large-latest",
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        "temperature": 0.7,
        "max_tokens": 4000
    }
    
    try:
        response = requests.post(
            "https://api.mistral.ai/v1/chat/completions",
            headers=headers,
            json=payload,
            timeout=120
        )
        
        if response.status_code == 200:
            data = response.json()
            return data['choices'][0]['message']['content'].strip()
        elif response.status_code == 429:
            time.sleep(2)  # Retry apr√®s rate limit
            return query_mistral_api(system_prompt, user_prompt)
        else:
            return None
            
    except Exception as e:
        print(f"Erreur Mistral API: {e}")
        return None

def generate_local_analysis(text, content_type, level):
    """Analyse locale de fallback (sans IA externe)"""
    
    # Analyse basique locale
    words = text.split()
    sentences = re.split(r'[.!?]+', text)
    
    # Concepts bas√©s sur la fr√©quence
    word_freq = {}
    for word in words:
        if len(word) > 4:  # Mots significatifs
            word_freq[word.lower()] = word_freq.get(word.lower(), 0) + 1
    
    top_concepts = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:5]
    
    return f"""
<section_resume>
## R√âSUM√â AUTOMATIQUE
Le texte analys√© contient {len(words)} mots et {len(sentences)} phrases.
Type de contenu d√©tect√©: {content_type}
Niveau estim√©: {level}

Contenu principal extrait automatiquement du document fourni.
</section_resume>

<section_concepts>
## CONCEPTS LES PLUS FR√âQUENTS
{chr(10).join([f"**{concept.title()}**: Terme important mentionn√© {freq} fois" for concept, freq in top_concepts])}
</section_concepts>

<section_questions_progressives>
## QUESTIONS DE R√âVISION AUTO-G√âN√âR√âES
### Niveau Facile:
1. Quels sont les mots-cl√©s principaux de ce cours ?
2. Quel est le th√®me g√©n√©ral abord√© ?
3. Combien de concepts principaux sont d√©velopp√©s ?

### Niveau Moyen:
1. Comment les diff√©rents concepts s'articulent-ils entre eux ?
2. Quelles sont les id√©es principales √† retenir ?
3. Quel est l'objectif p√©dagogique de ce contenu ?

### Niveau Difficile:
1. Analysez la structure argumentative du document
2. Proposez une synth√®se critique du contenu
</section_questions_progressives>

<section_plan_revision>
## PLAN DE R√âVISION SUGG√âR√â
**Jour 1-2**: Lecture attentive et identification des concepts
**Jour 3-4**: M√©morisation des d√©finitions principales  
**Jour 5-6**: Application et exercices pratiques
**Jour 7**: R√©vision g√©n√©rale et auto-√©valuation
</section_plan_revision>
"""

def parse_ai_response(response):
    """Parse la r√©ponse IA en sections structur√©es"""
    sections = [
        'resume', 'niveau', 'concepts', 'carte_mentale', 
        'questions_progressives', 'mn√©motechniques', 
        'plan_revision', 'ressources', 'evaluation'
    ]
    
    parsed_data = {}
    for section in sections:
        pattern = f'<section_{section}>(.*?)</section_{section}>'
        match = re.search(pattern, response, re.DOTALL)
        if match:
            parsed_data[section] = match.group(1).strip()
        else:
            parsed_data[section] = f"Section {section} non g√©n√©r√©e"
    
    return parsed_data

# Routes API am√©lior√©es
@app.route('/')
def index():
    return send_from_directory('.', 'index.html')

@app.route('/analyze', methods=['POST'])
def analyze():
    """Endpoint d'analyse principal am√©lior√©"""
    start_time = time.time()
    
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'Aucun fichier fourni'}), 400
            
        file = request.files['file']
        if not file.filename:
            return jsonify({'error': 'Nom de fichier vide'}), 400
        
        # Param√®tres de la requ√™te
        content_type = request.form.get('content_type', 'general')
        detail_level = request.form.get('detail_level', 'detailed')
        language = request.form.get('language', 'fr')
        
        print(f"üöÄ Nouvelle analyse - Type: {content_type}, Langue: {language}")
        
        # Lecture du fichier
        file_data = file.read()
        
        # OCR avec Tesseract
        tesseract_lang = analyzer.languages.get(language, 'fra+eng')
        extracted_text, ocr_error = analyzer.extract_text_with_tesseract(file_data, tesseract_lang)
        
        if ocr_error:
            return jsonify({'error': f"Erreur OCR: {ocr_error}"}), 500
        
        # Auto-d√©tection du type si pas sp√©cifi√©
        if content_type == 'general':
            content_type = analyzer.detect_content_type_auto(extracted_text)
            print(f"üìä Type auto-d√©tect√©: {content_type}")
        
        # Analyse avec IA
        ai_response = analyze_with_ai(extracted_text, content_type, detail_level)
        analysis_data = parse_ai_response(ai_response)
        
        # Stockage en session pour t√©l√©chargement
        session_id = f"session_{int(time.time())}"
        session_data[session_id] = {
            'analysis': analysis_data,
            'raw_text': extracted_text,
            'metadata': {
                'content_type': content_type,
                'language': language,
                'processing_time': round(time.time() - start_time, 2),
                'timestamp': datetime.now().isoformat()
            }
        }
        
        # G√©n√©ration de flashcards √† partir des concepts
        flashcards = generate_flashcards_from_concepts(analysis_data.get('concepts', ''))
        
        print(f"‚úÖ Analyse compl√®te en {round(time.time() - start_time, 2)}s")
        
        return jsonify({
            'success': True,
            'session_id': session_id,
            'summary': analysis_data.get('resume', ''),
            'level_analysis': analysis_data.get('niveau', ''),
            'concepts': analysis_data.get('concepts', ''),
            'mind_map': analysis_data.get('carte_mentale', ''),
            'progressive_quiz': analysis_data.get('questions_progressives', ''),
            'mnemonics': analysis_data.get('mn√©motechniques', ''),
            'study_plan': analysis_data.get('plan_revision', ''),
            'resources': analysis_data.get('ressources', ''),
            'self_evaluation': analysis_data.get('evaluation', ''),
            'flashcards': flashcards,
            'raw_text': extracted_text,
            'metadata': session_data[session_id]['metadata']
        })
        
    except Exception as e:
        print(f"‚ùå Erreur critique: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'error': 'Erreur interne du serveur',
            'details': str(e)
        }), 500

def generate_flashcards_from_concepts(concepts_text):
    """G√©n√®re des flashcards √† partir du texte des concepts"""
    flashcards = []
    
    # Parse les concepts du format "**Concept**: Definition"
    concept_matches = re.findall(r'\*\*([^*]+)\*\*:\s*([^\n]+)', concepts_text)
    
    for concept, definition in concept_matches[:8]:  # Max 8 flashcards
        flashcards.append({
            'question': f"Qu'est-ce que {concept.strip()} ?",
            'answer': definition.strip()
        })
    
    return flashcards

@app.route('/download/<session_id>')
def download_analysis(session_id):
    """T√©l√©chargement des r√©sultats d'analyse"""
    if session_id not in session_data:
        return jsonify({'error': 'Session non trouv√©e'}), 404
    
    data = session_data[session_id]
    
    # G√©n√©ration du contenu de t√©l√©chargement
    content = generate_download_content(data)
    
    return jsonify({
        'success': True,
        'content': content,
        'filename': f"analyse_cours_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    })

def generate_download_content(session_data):
    """G√©n√®re le contenu format√© pour t√©l√©chargement"""
    analysis = session_data['analysis']
    metadata = session_data['metadata']
    
    content = f"""
{'='*60}
                    ANALYSE DE COURS INTELLIGENTE
{'='*60}

G√©n√©r√©e le: {metadata['timestamp']}
Type de contenu: {metadata['content_type']}
Temps de traitement: {metadata['processing_time']}s

{'='*60}

{analysis.get('resume', '')}

{'='*60}
CONCEPTS CL√âS
{'='*60}
{analysis.get('concepts', '')}

{'='*60}
CARTE MENTALE
{'='*60}
{analysis.get('carte_mentale', '')}

{'='*60}
QUIZ PROGRESSIF
{'='*60}
{analysis.get('questions_progressives', '')}

{'='*60}
PLAN DE R√âVISION
{'='*60}
{analysis.get('plan_revision', '')}

{'='*60}
TEXTE BRUT EXTRAIT (OCR)
{'='*60}
{session_data['raw_text']}
"""
    
    return content

@app.route('/health')
def health_check():
    """V√©rification de l'√©tat du service"""
    # Test Tesseract
    tesseract_ok = False
    try:
        pytesseract.get_tesseract_version()
        tesseract_ok = True
    except:
        pass
    
    return jsonify({
        'status': 'OK',
        'services': {
            'tesseract_ocr': tesseract_ok,
            'mistral_api': bool(MISTRAL_API_KEY),
            'huggingface_api': bool(HUGGINGFACE_API_KEY),
            'ollama_local': requests.get(f"{OLLAMA_URL}/api/version", timeout=2).status_code == 200 if OLLAMA_URL else False
        },
        'timestamp': datetime.now().isoformat()
    })

@app.errorhandler(413)
def too_large(error):
    return jsonify({'error': 'Fichier trop volumineux (max 5 Mo)'}), 413

@app.errorhandler(500)
def internal_error(error):
    return jsonify({'error': 'Erreur interne du serveur'}), 500

if __name__ == '__main__':
    print("üöÄ ANALYSEUR DE COURS INTELLIGENT v2.0")
    print("="*50)
    print("üîç OCR: Tesseract (gratuit)")
    print("ü§ñ IA: Multi-provider (Mistral/HuggingFace/Ollama/Local)")
    print("üíæ Stockage: En m√©moire (session)")
    print("="*50)
    
    # D√©marrage selon l'environnement
    if os.getenv('VERCEL'):
        print("‚òÅÔ∏è Mode VERCEL")
    elif os.getenv('RAILWAY'):
        print("üöÇ Mode RAILWAY") 
    else:
        print("üíª Mode D√âVELOPPEMENT LOCAL")
        print("URL: http://127.0.0.1:5000")
        app.run(host='127.0.0.1', port=5000, debug=True)

